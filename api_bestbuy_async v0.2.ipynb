{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from time import perf_counter, sleep\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import quote_plus\n",
    "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
    "\n",
    "import config_bestbuy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "batch_size = 5\n",
    "delay = round(uniform(0, (batch_size*.25)), 1)\n",
    "if (delay%1*10)%2 != 0: delay = round(delay + .1, 1)\n",
    "print(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def to_matrix(x, n):\n",
    "    l = []\n",
    "    for i in range(x):\n",
    "        l.append(i+1)\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "\n",
    "async def ceiling_division(n, d):\n",
    "    return -(n // -d)\n",
    "\n",
    "\n",
    "async def insert_db(r, engine, db_cols, container, cursor_mark):\n",
    "\n",
    "    cols = ['nextCursorMark', 'total', 'totalPages', 'queryTime', 'totalTime', 'canonicalUrl', \n",
    "            'sku', 'name', 'type', 'startDate', 'new', 'activeUpdateDate', 'active', 'regularPrice', \n",
    "            'salePrice', 'clearance', 'onSale', 'categoryPath', 'customerReviewCount', 'customerReviewAverage', \n",
    "            'priceUpdateDate', 'itemUpdateDate', 'class', 'classId', 'subclass', 'subclassId', 'department', 'departmentId', \n",
    "            'theatricalReleaseDate', 'studio', 'manufacturer', 'modelNumber', 'condition', 'artistName', 'images', 'image', 'color']\n",
    "    bool_cols = [\"new\", \"active\", \"clearance\", \"onSale\"]\n",
    "    int_cols = [\"total\", \"totalPages\"]\n",
    "    float_cols = [\"queryTime\", \"totalTime\", \"regularPrice\", \"salePrice\", \"customerReviewCount\", \"customerReviewAverage\", 'theatricalReleaseDate']\n",
    "    date_cols = [\"startDate\", \"activeUpdateDate\", \"priceUpdateDate\", \"itemUpdateDate\"]\n",
    "    \n",
    "    with engine.connect() as cnx:\n",
    "        io = r.json()\n",
    "        # for product in io['products']:\n",
    "        #     product['cursorMark'] = cursor_mark\n",
    "        #     product['id'] = str(uuid.uuid4())\n",
    "        #     container.create_item(body=product)\n",
    "        \n",
    "        df_meta = pd.DataFrame(io)\n",
    "        df_meta = df_meta.iloc[:, :-1]\n",
    "        df_products = pd.DataFrame(io['products'])\n",
    "        df = df_meta.merge(df_products, how='inner', left_index=True, right_index=True)\n",
    "        df = df.loc[:, cols]\n",
    "        df.insert(0, 'request_timestamp', datetime.utcnow())\n",
    "\n",
    "        for col in df.columns.tolist():\n",
    "            if col in bool_cols:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('bool')\n",
    "            elif col in int_cols:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('int64')\n",
    "            elif col in float_cols:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('float64')\n",
    "            elif col in date_cols:\n",
    "                df.loc[:, col] = pd.to_datetime(df.loc[:, col], errors='coerce', infer_datetime_format=True)\n",
    "            else:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('str')\n",
    "                \n",
    "        df.to_sql(name='products', con=cnx, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "async def main(api_index=0, folder_index=0, page_size=100):\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    # folderpath, datename, engine, db_cols, last_update_date, container = await initialize(folder_index=api_index)\n",
    "    \n",
    "    folders = ['products', 'categories', 'stores', 'products_update']\n",
    "    datename = datetime.utcnow().strftime('%Y%m%d')\n",
    "    cosmos_endpoint = config_bestbuy.bestbuy_cosmosdb_end_point\n",
    "    cosmos_primary_key = config_bestbuy.bestbuy_cosmosdb_primary_key\n",
    "    client = CosmosClient(cosmos_endpoint, cosmos_primary_key)\n",
    "    db_name = 'BestBuyDB'\n",
    "    database = client.create_database_if_not_exists(id=db_name)\n",
    "    container_name = 'Products'\n",
    "    container = database.create_container_if_not_exists(\n",
    "        id=container_name,\n",
    "        partition_key=PartitionKey(path='/department'),\n",
    "        offer_throughput=400\n",
    "    )\n",
    "    \"\"\"\"\"\"\n",
    "    # path = config_bestbuy.path\n",
    "    path = config_bestbuy.path_test\n",
    "    foldername = f'best_buy_{datename}\\\\{folders[folder_index]}'\n",
    "    folderpath = os.path.join(path, foldername)\n",
    "\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "\n",
    "    \"\"\"\"\"\"\n",
    "    # db = os.path.join(config_bestbuy.path, 'bestbuy.db')\n",
    "    # conn_string = f'sqlite:///{db}'\n",
    "    # engine = create_engine(conn_string)\n",
    "\n",
    "    # # params = quote_plus(config_bestbuy.bestbuy_sql_odbc_string)\n",
    "    # # engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "    # with engine.connect() as cnx:\n",
    "    #     try:\n",
    "    #         sel_stmt = \"SELECT * FROM products LIMIT 0\"\n",
    "    #         df_db = pd.read_sql(sql=sel_stmt, con=cnx)\n",
    "    #         db_cols = df_db.columns.tolist()\n",
    "\n",
    "    #         last_update_stmt = 'SELECT MAX(itemUpdateDate) FROM products'\n",
    "    #         df_itemUpdateDate = pd.read_sql(sql=last_update_stmt, con=cnx)\n",
    "    #         last_update_date = df_itemUpdateDate.iloc[0, 0]\n",
    "            \n",
    "    #     except Exception as e:\n",
    "    #         db_cols = []\n",
    "    #         last_update_date = None\n",
    "    \n",
    "\n",
    "    async def api_bestbuy(page=1):\n",
    "        chunk_size = 1024 # 64 * 2**10\n",
    "        key = config_bestbuy.bestbuy_api_key\n",
    "        apis = ['products', 'categories', 'stores'] #, f'products(itemUpdateDate>{last_update_date}&active=*)']\n",
    "        url = f\"https://api.bestbuy.com/v1/{apis[api_index]}\"\n",
    "        payload = {\n",
    "            'apiKey': key, \n",
    "            'pageSize': page_size, \n",
    "            'format': 'json', \n",
    "            'show': 'all',\n",
    "            'page': page\n",
    "            }\n",
    "\n",
    "        delay = page/5\n",
    "        # delay = 0\n",
    "        # await asyncio.sleep(delay)\n",
    "        t1 = perf_counter()\n",
    "\n",
    "        # sem = asyncio.Semaphore(5)\n",
    "        connector = aiohttp.TCPConnector(limit=5)\n",
    "        # await asyncio.sleep(1)\n",
    "        async with aiohttp.ClientSession(connector=connector) as session:\n",
    "            # async with sem:\n",
    "            # async with sem, session.get(url, params=payload) as r:\n",
    "            async with session.get(url, params=payload) as r:\n",
    "                # r.status\n",
    "                data = await r.json(content_type=None) # content_type='text/html'\n",
    "                pg = data.get('currentPage', 0)\n",
    "                filename = f'best_buy_{datename}_{pg:05}.json'\n",
    "                filepath = os.path.join(folderpath, filename)\n",
    "\n",
    "                # with open(filepath, 'wb') as fd:\n",
    "                #     # data = json.dumps(await r.json(), indent=4)\n",
    "                #     async for chunk in r.content.iter_chunked(chunk_size):\n",
    "                #         fd.write(chunk)\n",
    "\n",
    "                with open(filepath, 'w') as f:\n",
    "                    json.dump(data, f, indent=4)\n",
    "            # insert_db(r=r, engine=engine, db_cols=db_cols, container=container, cursor_mark=nextcursorMark)\n",
    "        \n",
    "        t2 = perf_counter()\n",
    "        print(f'{pg=}', f'{delay=}', f'{t2-t1=}', f'{t2-t0=}', sep=' | ')\n",
    "        return data\n",
    "\n",
    "    \n",
    "    data = await api_bestbuy()\n",
    "    # print(pages)\n",
    "    pages = data.get('totalPages', 0)\n",
    "    tasks = (api_bestbuy(page=page+1) for page in range(pages))\n",
    "    await asyncio.gather(*tasks)\n",
    "    # batches = await to_matrix(pages, 5)\n",
    "    # tasks = [\n",
    "    #     api_bestbuy(page=1), api_bestbuy(page=2), api_bestbuy(page=3), api_bestbuy(page=4), api_bestbuy(page=5),\n",
    "    #     api_bestbuy(page=6), api_bestbuy(page=7), api_bestbuy(page=8), api_bestbuy(page=9), api_bestbuy(page=10)\n",
    "    # ]\n",
    "    # r = await api_bestbuy(page=pg, api_index=api_index, page_size=page_size, last_update_date=last_update_date)\n",
    "        \n",
    "    \n",
    "    print(f'fin: {perf_counter()-t0=}')\n",
    "    # return await asyncio.gather(*tasks)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # [0: 'products', 1: 'categories', 2: 'stores', 3: f'products(itemUpdateDate>{last_update_date}&active=*)']\n",
    "    # asyncio.run(main(api_index=0, folder_index=0, page_size=100))\n",
    "    # await main(api_index=0, folder_index=0, page_size=100)\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(main(api_index=0, folder_index=0, page_size=100))\n",
    "    loop.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: To query for updates or deltas since you last walked through the result set you can use the itemUpdateDate attribute. To ensure that your query results include changes to a product’s active/inactive status, add active=* to your query parameters. \n",
    "For example: .../v1/products(itemUpdateDate>2017-02-06T16:00:00&active=*)?format=json&pageSize=100&cursorMark=*&apiKey=YOUR_API_KEY\n",
    "For example: .../v1/products(itemUpdateDate>today&active=*)?format=json&pageSize=100&cursorMark=*&apiKey=YOUR_API_KEY\n",
    "\"https://api.bestbuy.com/v1/products(releaseDate>today)?format=json&show=sku,name,salePrice&apiKey=YourAPIKey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_with_concurrency(n, *tasks):\n",
    "    semaphore = asyncio.Semaphore(n)\n",
    "\n",
    "    async def sem_task(task):\n",
    "        async with semaphore:\n",
    "            return await task\n",
    "    return await asyncio.gather(*(sem_task(task) for task in tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/47675410/python-asyncio-aiohttp-valueerror-too-many-file-descriptors-in-select-on-win\n",
    "https://tutorialedge.net/python/concurrency/python-asyncio-semaphores-tutorial/\n",
    "https://stackoverflow.com/questions/48483348/how-to-limit-concurrency-with-python-asyncio\n",
    "https://stackoverflow.com/questions/56151929/aiohttp-with-asyncio-and-semaphores-returning-a-list-filled-with-nones\n",
    "https://stackoverflow.com/questions/40836800/python-asyncio-semaphore-in-async-await-function\n",
    "https://stackoverflow.com/questions/35196974/aiohttp-set-maximum-number-of-requests-per-second/43857526#43857526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Page = 1\n",
    "api_index = 0\n",
    "page_size = 100\n",
    "\n",
    "r = api_bestbuy_test(pg=Page, api_index=api_index, page_size=page_size)\n",
    "io = r.json()\n",
    "io['id'] = str(uuid.uuid4())\n",
    "io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['nextCursorMark', 'total', 'totalPages', 'queryTime', 'totalTime', 'canonicalUrl', 'sku', 'name', 'type', 'startDate', 'new', 'activeUpdateDate', 'active', 'regularPrice', 'salePrice', 'clearance', 'onSale', 'categoryPath', 'customerReviewCount', 'customerReviewAverage', 'priceUpdateDate', 'itemUpdateDate', 'class', 'classId', 'subclass', 'subclassId', 'department', 'departmentId', 'images', 'image', 'color']\n",
    "io = r.json()\n",
    "df_meta = pd.DataFrame(io)\n",
    "df_meta = df_meta.iloc[:, :-1]\n",
    "df_products = pd.DataFrame(io['products'])\n",
    "df = df_meta.merge(df_products, how='inner', left_index=True, right_index=True)\n",
    "df = df.loc[:, cols]\n",
    "df.insert(0, 'request_timestamp', datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalpages = set()\n",
    "for _ in range(io['totalPages']):\n",
    "    totalpages.add(_+1)\n",
    "\n",
    "totalpages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bestbuy.bestbuy_sql_odbc_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db = os.path.join(config_bestbuy.path, 'bestbuy.db')\n",
    "conn_string = f'sqlite:///{db}'\n",
    "engine = create_engine(conn_string)\n",
    "\n",
    "# params = quote_plus(config_bestbuy.bestbuy_sql_odbc_string)\n",
    "# engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "    \n",
    "with engine.connect() as cnx:\n",
    "    df_test = pd.read_sql(sql=\"select color from products_archive\", con=cnx)\n",
    "\n",
    "for col in df_test.columns.tolist():\n",
    "    print(col, df_test.loc[:, col].astype('str').apply(len).max(), sep= ' - ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(x, n):\n",
    "    l = []\n",
    "    for i in range(x):\n",
    "        l.append(i+1)\n",
    "    return [{_: l[i:i+n]} for _, i in enumerate(range(0, len(l), n))]\n",
    "\n",
    "\n",
    "batches = to_matrix(2244, 5)\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    print(batch.get(i), \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.utcnow().date()\n",
    "n_days = datetime.utcnow().date() - timedelta(days=2)\n",
    "n_hours = (today-n_days)/timedelta(seconds=1)\n",
    "n_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3410afedb74081d81603511028deadddc25ba0f01c14e0cb891e2c2473f81884"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
