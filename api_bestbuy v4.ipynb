{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from time import perf_counter, sleep\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import quote_plus\n",
    "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
    "\n",
    "import config_bestbuy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(folder_index=0):\n",
    "\n",
    "    folders = ['products', 'categories', 'stores', 'products_update']\n",
    "    datename = datetime.utcnow().strftime('%Y%m%d')\n",
    "    cosmos_endpoint = config_bestbuy.bestbuy_cosmosdb_end_point\n",
    "    cosmos_primary_key = config_bestbuy.bestbuy_cosmosdb_primary_key\n",
    "    client = CosmosClient(cosmos_endpoint, cosmos_primary_key)\n",
    "    db_name = 'BestBuyDB'\n",
    "    database = client.create_database_if_not_exists(id=db_name)\n",
    "    container_name = 'Products'\n",
    "    container = database.create_container_if_not_exists(\n",
    "        id=container_name,\n",
    "        partition_key=PartitionKey(path='/department'),\n",
    "        offer_throughput=400\n",
    "    )\n",
    "    path = config_bestbuy.path\n",
    "    foldername = f'best_buy_{datename}\\\\{folders[folder_index]}'\n",
    "    folderpath = os.path.join(path, foldername)\n",
    "\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "\n",
    "    db = os.path.join(config_bestbuy.path, 'bestbuy.db')\n",
    "    conn_string = f'sqlite:///{db}'\n",
    "    engine = create_engine(conn_string)\n",
    "\n",
    "    # params = quote_plus(config_bestbuy.bestbuy_sql_odbc_string)\n",
    "    # engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "    with engine.connect() as cnx:\n",
    "        try:\n",
    "            sel_stmt = \"SELECT * FROM products LIMIT 0\"\n",
    "            df_db = pd.read_sql(sql=sel_stmt, con=cnx)\n",
    "            db_cols = df_db.columns.tolist()\n",
    "\n",
    "            last_update_stmt = 'SELECT MAX(itemUpdateDate) FROM products'\n",
    "            df_itemUpdateDate = pd.read_sql(sql=last_update_stmt, con=cnx)\n",
    "            last_update_date = df_itemUpdateDate.iloc[0, 0]\n",
    "            \n",
    "        except Exception as e:\n",
    "            db_cols = []\n",
    "            last_update_date = None\n",
    "            \n",
    "    return folderpath, datename, engine, db_cols, last_update_date, container\n",
    "\n",
    "\n",
    "def api_bestbuy(cursorMark=\"*\", api_index=0, page_size=100, last_update_date=None):\n",
    "    key = config_bestbuy.bestbuy_api_key\n",
    "    apis = ['products', 'categories', 'stores', f'products(itemUpdateDate>{last_update_date}&active=*)']\n",
    "    url = f\"https://api.bestbuy.com/v1/{apis[api_index]}\"\n",
    "    payload = {\n",
    "        'apiKey': key, \n",
    "        'pageSize': page_size, \n",
    "        'format': 'json', \n",
    "        'show': 'all',\n",
    "        'cursorMark': cursorMark\n",
    "        }\n",
    "    r = requests.get(f'{url}', params=payload)\n",
    "\n",
    "    return r\n",
    "\n",
    "\n",
    "def insert_db(r, engine, db_cols, container, cursor_mark):\n",
    "\n",
    "    cols = ['nextCursorMark', 'total', 'totalPages', 'queryTime', 'totalTime', 'canonicalUrl', \n",
    "            'sku', 'name', 'type', 'startDate', 'new', 'activeUpdateDate', 'active', 'regularPrice', \n",
    "            'salePrice', 'clearance', 'onSale', 'categoryPath', 'customerReviewCount', 'customerReviewAverage', \n",
    "            'priceUpdateDate', 'itemUpdateDate', 'class', 'classId', 'subclass', 'subclassId', 'department', 'departmentId', \n",
    "            'theatricalReleaseDate', 'studio', 'manufacturer', 'modelNumber', 'condition', 'artistName', 'images', 'image', 'color']\n",
    "    bool_cols = [\"new\", \"active\", \"clearance\", \"onSale\"]\n",
    "    int_cols = [\"total\", \"totalPages\"]\n",
    "    float_cols = [\"queryTime\", \"totalTime\", \"regularPrice\", \"salePrice\", \"customerReviewCount\", \"customerReviewAverage\", 'theatricalReleaseDate']\n",
    "    date_cols = [\"startDate\", \"activeUpdateDate\", \"priceUpdateDate\", \"itemUpdateDate\"]\n",
    "    \n",
    "    with engine.connect() as cnx:\n",
    "        io = r.json()\n",
    "        # for product in io['products']:\n",
    "        #     product['cursorMark'] = cursor_mark\n",
    "        #     product['id'] = str(uuid.uuid4())\n",
    "        #     container.create_item(body=product)\n",
    "        \n",
    "        df_meta = pd.DataFrame(io)\n",
    "        df_meta = df_meta.iloc[:, :-1]\n",
    "        df_products = pd.DataFrame(io['products'])\n",
    "        df = df_meta.merge(df_products, how='inner', left_index=True, right_index=True)\n",
    "        df = df.loc[:, cols]\n",
    "        df.insert(0, 'request_timestamp', datetime.utcnow())\n",
    "\n",
    "        for col in df.columns.tolist():\n",
    "            if col in bool_cols:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('bool')\n",
    "            elif col in int_cols:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('int64')\n",
    "            elif col in float_cols:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('float64')\n",
    "            elif col in date_cols:\n",
    "                df.loc[:, col] = pd.to_datetime(df.loc[:, col], errors='coerce', infer_datetime_format=True)\n",
    "            else:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('str')\n",
    "                \n",
    "        df.to_sql(name='products', con=cnx, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "def main(api_index=0, page_size=100, db=False):\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    folderpath, datename, engine, db_cols, last_update_date, container = initialize(folder_index=api_index)\n",
    "    nextcursorMark = \"*\"\n",
    "    pg = 0\n",
    "    try:\n",
    "        pages = api_bestbuy(cursorMark=nextcursorMark, api_index=api_index, page_size=page_size, last_update_date=last_update_date).json()['totalPages']\n",
    "    except Exception as e:\n",
    "        pages = 0\n",
    "        print(f\"{pages=}: {(perf_counter()-t0)=}\")\n",
    "        quit()\n",
    "\n",
    "    print(f'{pages=}')\n",
    "    sleep(1)\n",
    "    t1 = perf_counter()\n",
    "\n",
    "    while True:\n",
    "        print(f'{pg=}', f'{nextcursorMark=}', f'{t1=}', f'{perf_counter()-t1=}', sep=' | ')\n",
    "        r = api_bestbuy(cursorMark=nextcursorMark, api_index=api_index, page_size=page_size, last_update_date=last_update_date)\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            try:\n",
    "                if len(r.json()['products']) == 0:\n",
    "                    print(f\"fin: {(perf_counter()-t0)=}\")\n",
    "                    break\n",
    "\n",
    "                if pages == 0:\n",
    "                    print(f\"{pages=}: {(perf_counter()-t0)=}\")\n",
    "                    break\n",
    "\n",
    "                nextcursorMark = r.json()['nextCursorMark']\n",
    "                pg += 1\n",
    "            \n",
    "            except (NameError, ValueError, KeyError) as e:\n",
    "                print(f'{e=}')\n",
    "                t1 = perf_counter()\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            finally:\n",
    "                pass\n",
    "            \n",
    "            filename = f'best_buy_{datename}_{pg:05}.json'\n",
    "            filepath = os.path.join(folderpath, filename)\n",
    "\n",
    "            # with open(filepath, 'w') as f:\n",
    "            #     json.dump(r.json(), f, indent=4)\n",
    "\n",
    "            if db:\n",
    "                insert_db(r=r, engine=engine, db_cols=db_cols, container=container, cursor_mark=nextcursorMark)\n",
    "\n",
    "        timer = perf_counter()-t1\n",
    "        if (pg)%5==0:\n",
    "            if timer<1:\n",
    "                sleep(1-timer)\n",
    "            t1 = perf_counter()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # [0: 'products', 1: 'categories', 2: 'stores', 3: f'products(itemUpdateDate>{last_update_date}&active=*)']\n",
    "    main(api_index=3, page_size=100, db=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: To query for updates or deltas since you last walked through the result set you can use the itemUpdateDate attribute. To ensure that your query results include changes to a productâ€™s active/inactive status, add active=* to your query parameters. \n",
    "For example: .../v1/products(itemUpdateDate>2017-02-06T16:00:00&active=*)?format=json&pageSize=100&cursorMark=*&apiKey=YOUR_API_KEY\n",
    "For example: .../v1/products(itemUpdateDate>today&active=*)?format=json&pageSize=100&cursorMark=*&apiKey=YOUR_API_KEY\n",
    "\"https://api.bestbuy.com/v1/products(releaseDate>today)?format=json&show=sku,name,salePrice&apiKey=YourAPIKey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_bestbuy_test(pg=1, api_index=0, page_size=100, last_update_date=None):\n",
    "    key = config_bestbuy.bestbuy_api_key\n",
    "    apis = ['products', 'categories', 'stores', f'products(itemUpdateDate>{last_update_date}&active=*)']\n",
    "    url = f\"https://api.bestbuy.com/v1/{apis[api_index]}\"\n",
    "    payload = {\n",
    "        'apiKey': key, \n",
    "        'pageSize': page_size, \n",
    "        'format': 'json', \n",
    "        'show': 'all', \n",
    "        'page': pg\n",
    "        }\n",
    "    r = requests.get(f'{url}', params=payload)\n",
    "\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Page = 1\n",
    "api_index = 0\n",
    "page_size = 100\n",
    "\n",
    "r = api_bestbuy_test(pg=Page, api_index=api_index, page_size=page_size)\n",
    "io = r.json()\n",
    "io['id'] = str(uuid.uuid4())\n",
    "io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['nextCursorMark', 'total', 'totalPages', 'queryTime', 'totalTime', 'canonicalUrl', 'sku', 'name', 'type', 'startDate', 'new', 'activeUpdateDate', 'active', 'regularPrice', 'salePrice', 'clearance', 'onSale', 'categoryPath', 'customerReviewCount', 'customerReviewAverage', 'priceUpdateDate', 'itemUpdateDate', 'class', 'classId', 'subclass', 'subclassId', 'department', 'departmentId', 'images', 'image', 'color']\n",
    "io = r.json()\n",
    "df_meta = pd.DataFrame(io)\n",
    "df_meta = df_meta.iloc[:, :-1]\n",
    "df_products = pd.DataFrame(io['products'])\n",
    "df = df_meta.merge(df_products, how='inner', left_index=True, right_index=True)\n",
    "df = df.loc[:, cols]\n",
    "df.insert(0, 'request_timestamp', datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalpages = set()\n",
    "for _ in range(io['totalPages']):\n",
    "    totalpages.add(_+1)\n",
    "\n",
    "totalpages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bestbuy.bestbuy_sql_odbc_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color - 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = os.path.join(config_bestbuy.path, 'bestbuy.db')\n",
    "conn_string = f'sqlite:///{db}'\n",
    "engine = create_engine(conn_string)\n",
    "\n",
    "# params = quote_plus(config_bestbuy.bestbuy_sql_odbc_string)\n",
    "# engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "    \n",
    "with engine.connect() as cnx:\n",
    "    df_test = pd.read_sql(sql=\"select color from products_archive\", con=cnx)\n",
    "\n",
    "for col in df_test.columns.tolist():\n",
    "    print(col, df_test.loc[:, col].astype('str').apply(len).max(), sep= ' - ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172800.0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.utcnow().date()\n",
    "n_days = datetime.utcnow().date() - timedelta(days=2)\n",
    "n_hours = (today-n_days)/timedelta(seconds=1)\n",
    "n_hours"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3410afedb74081d81603511028deadddc25ba0f01c14e0cb891e2c2473f81884"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
